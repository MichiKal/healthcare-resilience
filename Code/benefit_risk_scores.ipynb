{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate doctors benefit & risk score\n",
    "* use static network structure for estimation\n",
    "* use adjacency matrix and cotor info files for calculation (number of patients, maximal capacity, shared patients,..)\n",
    "* B and R for every doctor of each speciality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from os.path import join\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### simulation settings\n",
    "min_pats = 2\n",
    "max_distance = 100\n",
    "ptype = 'total'\n",
    "ctype = 'hour-based'\n",
    "tf = 'quarterly'\n",
    "network = 'Ã–sterreich'\n",
    "threshold = 0.9\n",
    "\n",
    "doc_list = ['IM','KI','PSY','ORTR','RAD','DER','URO','HNO','CH','NEU','AU','GGH','AM']\n",
    "risk_benefit = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in doc_list:\n",
    "    doc_file = 'doctor_info_bez={}_spec={}_ptype={}_ctype={}_tf={}_th={}.csv'.format(network, doc, ptype,\n",
    "                                                                                     ctype, tf, threshold)  \n",
    "    doctor_info = pd.read_csv(join('data', doc_file), delimiter=',')\n",
    "    doc_IDs = doctor_info['adj_index']\n",
    "\n",
    "    ### load adjacency matrix\n",
    "    adj = sparse.load_npz('data/adj_all_doctors.npz')\n",
    "    adj = adj.todense()\n",
    "    # load distance matrix between docs\n",
    "    dist_docs = sparse.load_npz('data/DistanceMatrixDocs.npz')\n",
    "    dist_docs = dist_docs.todense()\n",
    "\n",
    "    ### set connections with less than min_pats to zero\n",
    "    adj[adj<min_pats] = 0\n",
    "\n",
    "    ### set connections further than max distance to zero\n",
    "    adj[dist_docs>max_distance] = 0\n",
    "    adj = adj[np.ix_(doc_IDs, doc_IDs)]\n",
    "\n",
    "    ### set diagonal to zero\n",
    "    np.fill_diagonal(adj,0)\n",
    "    adj = np.asarray(adj)\n",
    "\n",
    "    doctor_info['initial_free_capacity'] = doctor_info.capacity - doctor_info.number_of_patients\n",
    "\n",
    "    doctor_info['connections'] = ''\n",
    "    doctor_info['num_of_connections'] = 0\n",
    "    for d in doctor_info.index.values:\n",
    "        doctor_info.at[d,'connections'] = list(np.where(adj[d,:]>0)[0])\n",
    "        doctor_info.at[d,'num_of_connections'] = len(list(np.where(adj[d,:]>0)[0]))\n",
    "\n",
    "    ## Risk\n",
    "    #* R_i = mean( min( (Nj + Ni * wj)/Cj, 1) )j\n",
    "\n",
    "    adj = adj.astype(float,copy=False)\n",
    "\n",
    "    for i in range(len(adj)):\n",
    "        adj[:,i] = adj[:,i]/np.sum(adj[:,i])\n",
    "\n",
    "    doctor_info['Risk'] = 0 \n",
    "    for d in doctor_info.index.values:\n",
    "        N_i = doctor_info.loc[d,'number_of_patients'].item()\n",
    "        connect = np.asarray(doctor_info.loc[d,'connections'])\n",
    "        l = []\n",
    "        for c in connect:\n",
    "            w_j = adj[c,d]\n",
    "            N_j = doctor_info.loc[c,'number_of_patients'].item()\n",
    "            C_j = doctor_info.loc[c,'capacity'].item()\n",
    "            l.append(np.min([(N_j+N_i*w_j)/C_j,1]))\n",
    "        if len(l)>0:\n",
    "            doctor_info.loc[d,'Risk'] = np.mean(np.asarray(l))\n",
    "        else:\n",
    "            doctor_info.loc[d,'Risk'] = np.nan\n",
    "\n",
    "    ## Benefit\n",
    "    #* B_i = initial free capacity of i\n",
    "\n",
    "    doctor_info['Benefit'] = 0 \n",
    "    for d in doctor_info.index.values:\n",
    "        doctor_info.loc[d,'Benefit'] = doctor_info.loc[d,'capacity'] - doctor_info.loc[d,'number_of_patients']\n",
    "        \n",
    "        \n",
    "        \n",
    "    ### normalize benefit score\n",
    "    normalized_df=(doctor_info.Benefit-np.min(doctor_info.Benefit))/(np.max(doctor_info.Benefit)-np.min(doctor_info.Benefit))\n",
    "    doctor_info.Benefit = normalized_df\n",
    "    \n",
    "    \n",
    "    doctor_info = doctor_info.drop(columns=['connections','number_of_patients','capacity','gemeinde']).round(3)\n",
    "    doctor_info['specialty'] = doc\n",
    "    \n",
    "    ### combine with other docs\n",
    "    risk_benefit = pd.concat([risk_benefit,doctor_info])\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_benefit.rename(columns={'adj_index':'docid'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_benefit = risk_benefit.sort_values('docid').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_benefit.to_csv('results/Risk_Benefit_table.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
